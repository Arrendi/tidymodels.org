---
title: "Iterative Optimzation of a Classification Model"
---

<script src="/rmarkdown-libs/jquery/jquery.min.js"></script>
<script src="/rmarkdown-libs/elevate-section-attrs/elevate-section-attrs.js"></script>


<p>The cell segmentation data from <a href="http://www.biomedcentral.com/1471-2105/8/340">Hill, LaPan, Li and Haney (2007)</a> will be used to demonstrate tuning for a classification model. For these data, the predictors are aspects of cells (like size, shape, etc.). These cells are measured using image analysis and manual curation of the cells are used to determine if the boundaries of the cells were adequately captured. The outcome is either poorly segmented (<code>PS</code>) or well segmented (<code>WS</code>). The point of the analysis is to predict whether <em>future</em> cells were properly delineated. The predictors tend to be highly correlated.</p>
<p>After first loading the data set, we remove indicators for the cell identifier, the original author’s training/test allocation, and two predictors that are scientifically unimportant. A new training/test split is created and a scheme for 10-fold cross-validation is also created.</p>
<pre class="r"><code>library(tidymodels)
library(tune)
library(kernlab)
library(modeldata)

# Load data
data(cells)

cells &lt;-
  cells %&gt;%
  select(-case, -contains(&quot;Centroid&quot;))

set.seed(8567)
tr_te_split &lt;- initial_split(cells)

seg_train &lt;- training(tr_te_split)
seg_test  &lt;-  testing(tr_te_split)

set.seed(5121)
folds &lt;- vfold_cv(seg_train, repeats = 2)</code></pre>
<div id="defining-the-tuning-scheme" class="section level2">
<h2>Defining the tuning scheme</h2>
<p>Since the predictors are highly correlated, we can used a recipe to convert the original predictors to principal component scores. There is also slight class imbalance in these data; about 64% of the data are poorly segmented. To mitigate this, the data will be down-sampled at the end of the pre-processing such that the number of poorly and well segmented cells occur with equal frequency. A recipe will be used to process the data. However, the number of principal components will need to be tuned so that we have enough (but not too many) representations of the data.</p>
<pre class="r"><code>seg_pre_proc &lt;-
  recipe(class ~ ., data = seg_train) %&gt;%
  step_YeoJohnson(all_predictors()) %&gt;%
  step_normalize(all_predictors()) %&gt;%
  step_pca(all_predictors(), num_comp = tune()) %&gt;%
  step_downsample(Class)</code></pre>
<p>Like the original analysis, a support vector machine will be used to model the data. A radial basis function (RBF) kernel will be used and its main parameter (<span class="math inline">\(\sigma\)</span>) will be tuned. Additionally, the main SVM parameter, the cost value, also needs optimization.</p>
<pre class="r"><code>svm_mod &lt;-
  svm_rbf(mode = &quot;classification&quot;, cost = tune(), rbf_sigma = tune()) %&gt;%
  set_engine(&quot;kernlab&quot;)</code></pre>
<p>These two objects will be combined into a single object via the <code>workflow()</code> function from the <code>workflows</code> package and this object will be used to fuel the optimization process.</p>
<pre class="r"><code>library(workflows) 

svm_wflow &lt;-
  workflow() %&gt;%
  add_model(svm_mod) %&gt;%
  add_recipe(seg_pre_proc)</code></pre>
<p>From this object, we can derive information about what parameters are slated to be tuned. A parameter set is derived:</p>
<pre class="r"><code>svm_set &lt;- parameters(svm_wflow)
svm_set
#&gt; Collection of 3 parameters for tuning
#&gt; 
#&gt;         id parameter type object class
#&gt;       cost           cost    nparam[+]
#&gt;  rbf_sigma      rbf_sigma    nparam[+]
#&gt;   num_comp       num_comp    nparam[+]</code></pre>
<p>The note about finalization occurs because the potential range for the number of principal components is determined by the number of predictors. For that reason, the parameter cannot be automatically initialized. A member of the parameter set can be modified using the <code>update()</code> function. Let’s constrain the search to one to twenty components:</p>
<pre class="r"><code>svm_set &lt;- svm_set %&gt;% update(num_comp = num_comp(c(1, 20)))</code></pre>
</div>
<div id="sequential-tuning" class="section level2">
<h2>Sequential tuning</h2>
<p>Bayesian optimization is a sequential method that uses a model to predict new candidate parameters for assessment. When scoring potential parameter value, the mean and variance of performance are predicted. The strategy used to define how these two statistical quantities are used is defined by an <em>acquisition function</em>.</p>
<p>For example, one approach for scoring new candidates is to use a confidence bound. Suppose accuracy is being optimized. For a metric that we want to maximize, a lower confidence bound can be used. The multiplier on the standard error (denoted as <span class="math inline">\(\kappa\)</span>) is a value that can be used to make trade-offs between <em>exploration</em> and <em>exploitation</em>.</p>
<ul>
<li><p><em>exploration</em> means that the search will consider candidates in untested space</p></li>
<li><p><em>exploitation</em> focuses in areas where the previous best results occurred.</p></li>
</ul>
<p>The variance predicted by the Bayesian model is mostly spatial variation; the value will be large for candidate values that are not close to values that have already been evaluated. If the standard error multiplier is high, the search process will be more likely to avoid areas without candidate values in the vicinity.</p>
<p>We’ll use another acquisition function, <em>expected improvement</em>, that calculates the determines which candidates likely to to be helpful relative to the current best results. This is the default acquisition function.</p>
<pre class="r"><code>set.seed(1291)
search_res &lt;- 
  tune_bayes(
    svm_wflow, 
    resamples = folds,
    # To use non-default parameter ranges
    param_info = svm_set,
    # Generate five at semi-random to start
    initial = 3,
    iter = 30,
    # How to measure performance?
    metrics = metric_set(roc_auc),
    control = control_bayes(no_improve = 20, verbose = TRUE)
  )
#&gt; 
#&gt; &gt;  Generating a set of 3 initial parameter results
#&gt; ✓ Initialization complete
#&gt; 
#&gt; Optimizing roc_auc using the expected improvement
#&gt; 
#&gt; ── Iteration 1 ──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
#&gt; 
#&gt; i Current best:      roc_auc=0.8653 (@iter 0)
#&gt; i Gaussian process model
#&gt; ✓ Gaussian process model
#&gt; i Generating 5000 candidates
#&gt; i Predicted candidates
#&gt; i cost=0.00382, rbf_sigma=5.23e-06, num_comp=3
#&gt; i Estimating performance
#&gt; ✓ Estimating performance
#&gt; ⓧ Newest results:    roc_auc=0.8521 (+/-0.00759)
#&gt; 
#&gt; ── Iteration 2 ──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
#&gt; 
#&gt; i Current best:      roc_auc=0.8653 (@iter 0)
#&gt; i Gaussian process model
#&gt; ✓ Gaussian process model
#&gt; i Generating 5000 candidates
#&gt; i Predicted candidates
#&gt; i cost=30.3, rbf_sigma=1.2e-10, num_comp=20
#&gt; i Estimating performance
#&gt; ✓ Estimating performance
#&gt; ⓧ Newest results:    roc_auc=0.865 (+/-0.00694)
#&gt; 
#&gt; ── Iteration 3 ──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
#&gt; 
#&gt; i Current best:      roc_auc=0.8653 (@iter 0)
#&gt; i Gaussian process model
#&gt; ✓ Gaussian process model
#&gt; i Generating 5000 candidates
#&gt; i Predicted candidates
#&gt; i cost=0.021, rbf_sigma=0.996, num_comp=3
#&gt; i Estimating performance
#&gt; ✓ Estimating performance
#&gt; ⓧ Newest results:    roc_auc=0.8562 (+/-0.00732)
#&gt; 
#&gt; ── Iteration 4 ──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
#&gt; 
#&gt; i Current best:      roc_auc=0.8653 (@iter 0)
#&gt; i Gaussian process model
#&gt; ✓ Gaussian process model
#&gt; i Generating 5000 candidates
#&gt; i Predicted candidates
#&gt; i cost=0.00168, rbf_sigma=1.67e-10, num_comp=20
#&gt; i Estimating performance
#&gt; ✓ Estimating performance
#&gt; ⓧ Newest results:    roc_auc=0.7917 (+/-0.034)
#&gt; 
#&gt; ── Iteration 5 ──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
#&gt; 
#&gt; i Current best:      roc_auc=0.8653 (@iter 0)
#&gt; i Gaussian process model
#&gt; ✓ Gaussian process model
#&gt; i Generating 5000 candidates
#&gt; i Predicted candidates
#&gt; i cost=0.001, rbf_sigma=1.27e-09, num_comp=8
#&gt; i Estimating performance
#&gt; ✓ Estimating performance
#&gt; ⓧ Newest results:    roc_auc=0.7922 (+/-0.0341)
#&gt; 
#&gt; ── Iteration 6 ──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
#&gt; 
#&gt; i Current best:      roc_auc=0.8653 (@iter 0)
#&gt; i Gaussian process model
#&gt; ✓ Gaussian process model
#&gt; i Generating 5000 candidates
#&gt; i Predicted candidates
#&gt; i cost=0.35, rbf_sigma=2.28e-06, num_comp=3
#&gt; i Estimating performance
#&gt; ✓ Estimating performance
#&gt; ⓧ Newest results:    roc_auc=0.8521 (+/-0.00759)
#&gt; 
#&gt; ── Iteration 7 ──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
#&gt; 
#&gt; i Current best:      roc_auc=0.8653 (@iter 0)
#&gt; i Gaussian process model
#&gt; ✓ Gaussian process model
#&gt; i Generating 5000 candidates
#&gt; i Predicted candidates
#&gt; i cost=1.08, rbf_sigma=0.917, num_comp=19
#&gt; i Estimating performance
#&gt; ✓ Estimating performance
#&gt; ⓧ Newest results:    roc_auc=0.7479 (+/-0.0117)
#&gt; 
#&gt; ── Iteration 8 ──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
#&gt; 
#&gt; i Current best:      roc_auc=0.8653 (@iter 0)
#&gt; i Gaussian process model
#&gt; ✓ Gaussian process model
#&gt; i Generating 5000 candidates
#&gt; i Predicted candidates
#&gt; i cost=0.151, rbf_sigma=0.000304, num_comp=4
#&gt; i Estimating performance
#&gt; ✓ Estimating performance
#&gt; ⓧ Newest results:    roc_auc=0.854 (+/-0.0075)
#&gt; 
#&gt; ── Iteration 9 ──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
#&gt; 
#&gt; i Current best:      roc_auc=0.8653 (@iter 0)
#&gt; i Gaussian process model
#&gt; ✓ Gaussian process model
#&gt; i Generating 5000 candidates
#&gt; i Predicted candidates
#&gt; i cost=0.00103, rbf_sigma=0.533, num_comp=8
#&gt; i Estimating performance
#&gt; ✓ Estimating performance
#&gt; ♥ Newest results:    roc_auc=0.867 (+/-0.00835)
#&gt; 
#&gt; ── Iteration 10 ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
#&gt; 
#&gt; i Current best:      roc_auc=0.867 (@iter 9)
#&gt; i Gaussian process model
#&gt; ✓ Gaussian process model
#&gt; i Generating 5000 candidates
#&gt; i Predicted candidates
#&gt; i cost=2.81, rbf_sigma=1.01e-10, num_comp=18
#&gt; i Estimating performance
#&gt; ✓ Estimating performance
#&gt; ⓧ Newest results:    roc_auc=0.8609 (+/-0.00739)
#&gt; 
#&gt; ── Iteration 11 ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
#&gt; 
#&gt; i Current best:      roc_auc=0.867 (@iter 9)
#&gt; i Gaussian process model
#&gt; ✓ Gaussian process model
#&gt; i Generating 5000 candidates
#&gt; i Predicted candidates
#&gt; i cost=31.1, rbf_sigma=1.22e-06, num_comp=12
#&gt; i Estimating performance
#&gt; ✓ Estimating performance
#&gt; ⓧ Newest results:    roc_auc=0.8624 (+/-0.00742)
#&gt; 
#&gt; ── Iteration 12 ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
#&gt; 
#&gt; i Current best:      roc_auc=0.867 (@iter 9)
#&gt; i Gaussian process model
#&gt; ✓ Gaussian process model
#&gt; i Generating 5000 candidates
#&gt; i Predicted candidates
#&gt; i cost=29.9, rbf_sigma=0.878, num_comp=9
#&gt; i Estimating performance
#&gt; ✓ Estimating performance
#&gt; ⓧ Newest results:    roc_auc=0.8342 (+/-0.00723)
#&gt; 
#&gt; ── Iteration 13 ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
#&gt; 
#&gt; i Current best:      roc_auc=0.867 (@iter 9)
#&gt; i Gaussian process model
#&gt; ✓ Gaussian process model
#&gt; i Generating 5000 candidates
#&gt; i Predicted candidates
#&gt; i cost=10.9, rbf_sigma=1.18e-08, num_comp=14
#&gt; i Estimating performance
#&gt; ✓ Estimating performance
#&gt; ⓧ Newest results:    roc_auc=0.862 (+/-0.00728)
#&gt; 
#&gt; ── Iteration 14 ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
#&gt; 
#&gt; i Current best:      roc_auc=0.867 (@iter 9)
#&gt; i Gaussian process model
#&gt; ✓ Gaussian process model
#&gt; i Generating 5000 candidates
#&gt; i Predicted candidates
#&gt; i cost=31.5, rbf_sigma=4.99e-09, num_comp=2
#&gt; i Estimating performance
#&gt; ✓ Estimating performance
#&gt; ⓧ Newest results:    roc_auc=0.7926 (+/-0.0108)
#&gt; 
#&gt; ── Iteration 15 ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
#&gt; 
#&gt; i Current best:      roc_auc=0.867 (@iter 9)
#&gt; i Gaussian process model
#&gt; ✓ Gaussian process model
#&gt; i Generating 5000 candidates
#&gt; i Predicted candidates
#&gt; i cost=0.0226, rbf_sigma=1.21e-10, num_comp=2
#&gt; i Estimating performance
#&gt; ✓ Estimating performance
#&gt; ⓧ Newest results:    roc_auc=0.7358 (+/-0.0288)
#&gt; 
#&gt; ── Iteration 16 ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
#&gt; 
#&gt; i Current best:      roc_auc=0.867 (@iter 9)
#&gt; i Gaussian process model
#&gt; ✓ Gaussian process model
#&gt; i Generating 5000 candidates
#&gt; i Predicted candidates
#&gt; i cost=0.00334, rbf_sigma=0.000403, num_comp=12
#&gt; i Estimating performance
#&gt; ✓ Estimating performance
#&gt; ⓧ Newest results:    roc_auc=0.8627 (+/-0.00744)
#&gt; 
#&gt; ── Iteration 17 ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
#&gt; 
#&gt; i Current best:      roc_auc=0.867 (@iter 9)
#&gt; i Gaussian process model
#&gt; ✓ Gaussian process model
#&gt; i Generating 5000 candidates
#&gt; i Predicted candidates
#&gt; i cost=0.00343, rbf_sigma=2.71e-06, num_comp=20
#&gt; i Estimating performance
#&gt; ✓ Estimating performance
#&gt; ⓧ Newest results:    roc_auc=0.865 (+/-0.00694)
#&gt; 
#&gt; ── Iteration 18 ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
#&gt; 
#&gt; i Current best:      roc_auc=0.867 (@iter 9)
#&gt; i Gaussian process model
#&gt; ✓ Gaussian process model
#&gt; i Generating 5000 candidates
#&gt; i Predicted candidates
#&gt; i cost=24.6, rbf_sigma=0.000327, num_comp=20
#&gt; i Estimating performance
#&gt; ✓ Estimating performance
#&gt; ⓧ Newest results:    roc_auc=0.8648 (+/-0.0073)
#&gt; 
#&gt; ── Iteration 19 ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
#&gt; 
#&gt; i Current best:      roc_auc=0.867 (@iter 9)
#&gt; i Gaussian process model
#&gt; ✓ Gaussian process model
#&gt; i Generating 5000 candidates
#&gt; i Predicted candidates
#&gt; i cost=0.237, rbf_sigma=5.91e-05, num_comp=17
#&gt; i Estimating performance
#&gt; ✓ Estimating performance
#&gt; ⓧ Newest results:    roc_auc=0.8599 (+/-0.00741)
#&gt; 
#&gt; ── Iteration 20 ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
#&gt; 
#&gt; i Current best:      roc_auc=0.867 (@iter 9)
#&gt; i Gaussian process model
#&gt; ✓ Gaussian process model
#&gt; i Generating 5000 candidates
#&gt; i Predicted candidates
#&gt; i cost=0.00972, rbf_sigma=0.0175, num_comp=9
#&gt; i Estimating performance
#&gt; ✓ Estimating performance
#&gt; ♥ Newest results:    roc_auc=0.8685 (+/-0.00754)
#&gt; 
#&gt; ── Iteration 21 ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
#&gt; 
#&gt; i Current best:      roc_auc=0.8685 (@iter 20)
#&gt; i Gaussian process model
#&gt; ✓ Gaussian process model
#&gt; i Generating 5000 candidates
#&gt; i Predicted candidates
#&gt; i cost=28.8, rbf_sigma=0.0263, num_comp=1
#&gt; i Estimating performance
#&gt; ✓ Estimating performance
#&gt; ⓧ Newest results:    roc_auc=0.7531 (+/-0.0111)
#&gt; 
#&gt; ── Iteration 22 ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
#&gt; 
#&gt; i Current best:      roc_auc=0.8685 (@iter 20)
#&gt; i Gaussian process model
#&gt; ✓ Gaussian process model
#&gt; i Generating 5000 candidates
#&gt; i Predicted candidates
#&gt; i cost=8.03, rbf_sigma=4.24e-05, num_comp=8
#&gt; i Estimating performance
#&gt; ✓ Estimating performance
#&gt; ⓧ Newest results:    roc_auc=0.8653 (+/-0.00748)
#&gt; 
#&gt; ── Iteration 23 ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
#&gt; 
#&gt; i Current best:      roc_auc=0.8685 (@iter 20)
#&gt; i Gaussian process model
#&gt; ✓ Gaussian process model
#&gt; i Generating 5000 candidates
#&gt; i Predicted candidates
#&gt; i cost=0.00211, rbf_sigma=2.23e-08, num_comp=20
#&gt; i Estimating performance
#&gt; ✓ Estimating performance
#&gt; ⓧ Newest results:    roc_auc=0.865 (+/-0.00694)
#&gt; 
#&gt; ── Iteration 24 ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
#&gt; 
#&gt; i Current best:      roc_auc=0.8685 (@iter 20)
#&gt; i Gaussian process model
#&gt; ✓ Gaussian process model
#&gt; i Generating 5000 candidates
#&gt; i Predicted candidates
#&gt; i cost=0.00123, rbf_sigma=4.31e-08, num_comp=1
#&gt; i Estimating performance
#&gt; ✓ Estimating performance
#&gt; ⓧ Newest results:    roc_auc=0.7031 (+/-0.0255)
#&gt; 
#&gt; ── Iteration 25 ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
#&gt; 
#&gt; i Current best:      roc_auc=0.8685 (@iter 20)
#&gt; i Gaussian process model
#&gt; ✓ Gaussian process model
#&gt; i Generating 5000 candidates
#&gt; i Predicted candidates
#&gt; i cost=0.00125, rbf_sigma=1.2e-07, num_comp=10
#&gt; i Estimating performance
#&gt; ✓ Estimating performance
#&gt; ⓧ Newest results:    roc_auc=0.8639 (+/-0.00743)
#&gt; 
#&gt; ── Iteration 26 ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
#&gt; 
#&gt; i Current best:      roc_auc=0.8685 (@iter 20)
#&gt; i Gaussian process model
#&gt; ✓ Gaussian process model
#&gt; i Generating 5000 candidates
#&gt; i Predicted candidates
#&gt; i cost=0.00425, rbf_sigma=1.82e-07, num_comp=15
#&gt; i Estimating performance
#&gt; ✓ Estimating performance
#&gt; ⓧ Newest results:    roc_auc=0.8608 (+/-0.00706)
#&gt; 
#&gt; ── Iteration 27 ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
#&gt; 
#&gt; i Current best:      roc_auc=0.8685 (@iter 20)
#&gt; i Gaussian process model
#&gt; ✓ Gaussian process model
#&gt; i Generating 5000 candidates
#&gt; i Predicted candidates
#&gt; i cost=14.5, rbf_sigma=1.31e-10, num_comp=10
#&gt; i Estimating performance
#&gt; ✓ Estimating performance
#&gt; ⓧ Newest results:    roc_auc=0.8639 (+/-0.00743)
#&gt; 
#&gt; ── Iteration 28 ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
#&gt; 
#&gt; i Current best:      roc_auc=0.8685 (@iter 20)
#&gt; i Gaussian process model
#&gt; ✓ Gaussian process model
#&gt; i Generating 5000 candidates
#&gt; i Predicted candidates
#&gt; i cost=29.7, rbf_sigma=1.77e-10, num_comp=13
#&gt; i Estimating performance
#&gt; ✓ Estimating performance
#&gt; ⓧ Newest results:    roc_auc=0.8624 (+/-0.00734)
#&gt; 
#&gt; ── Iteration 29 ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
#&gt; 
#&gt; i Current best:      roc_auc=0.8685 (@iter 20)
#&gt; i Gaussian process model
#&gt; ✓ Gaussian process model
#&gt; i Generating 5000 candidates
#&gt; i Predicted candidates
#&gt; i cost=19.1, rbf_sigma=2.54e-07, num_comp=20
#&gt; i Estimating performance
#&gt; ✓ Estimating performance
#&gt; ⓧ Newest results:    roc_auc=0.865 (+/-0.00694)
#&gt; 
#&gt; ── Iteration 30 ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
#&gt; 
#&gt; i Current best:      roc_auc=0.8685 (@iter 20)
#&gt; i Gaussian process model
#&gt; ✓ Gaussian process model
#&gt; i Generating 5000 candidates
#&gt; i Predicted candidates
#&gt; i cost=0.00107, rbf_sigma=0.00336, num_comp=20
#&gt; i Estimating performance
#&gt; ✓ Estimating performance
#&gt; ⓧ Newest results:    roc_auc=0.8662 (+/-0.00692)</code></pre>
<p>The resulting tibble is a stacked set of rows of the <code>rsample</code> object with an additional column for the iteration number:</p>
<pre class="r"><code>search_res
#&gt; #  10-fold cross-validation repeated 2 times 
#&gt; # A tibble: 620 x 6
#&gt;    splits             id      id2    .metrics         .notes           .iter
#&gt;  * &lt;list&gt;             &lt;chr&gt;   &lt;chr&gt;  &lt;list&gt;           &lt;list&gt;           &lt;dbl&gt;
#&gt;  1 &lt;split [1.4K/152]&gt; Repeat1 Fold01 &lt;tibble [3 × 6]&gt; &lt;tibble [0 × 1]&gt;     0
#&gt;  2 &lt;split [1.4K/152]&gt; Repeat1 Fold02 &lt;tibble [3 × 6]&gt; &lt;tibble [0 × 1]&gt;     0
#&gt;  3 &lt;split [1.4K/152]&gt; Repeat1 Fold03 &lt;tibble [3 × 6]&gt; &lt;tibble [0 × 1]&gt;     0
#&gt;  4 &lt;split [1.4K/152]&gt; Repeat1 Fold04 &lt;tibble [3 × 6]&gt; &lt;tibble [0 × 1]&gt;     0
#&gt;  5 &lt;split [1.4K/152]&gt; Repeat1 Fold05 &lt;tibble [3 × 6]&gt; &lt;tibble [0 × 1]&gt;     0
#&gt;  6 &lt;split [1.4K/151]&gt; Repeat1 Fold06 &lt;tibble [3 × 6]&gt; &lt;tibble [0 × 1]&gt;     0
#&gt;  7 &lt;split [1.4K/151]&gt; Repeat1 Fold07 &lt;tibble [3 × 6]&gt; &lt;tibble [0 × 1]&gt;     0
#&gt;  8 &lt;split [1.4K/151]&gt; Repeat1 Fold08 &lt;tibble [3 × 6]&gt; &lt;tibble [0 × 1]&gt;     0
#&gt;  9 &lt;split [1.4K/151]&gt; Repeat1 Fold09 &lt;tibble [3 × 6]&gt; &lt;tibble [0 × 1]&gt;     0
#&gt; 10 &lt;split [1.4K/151]&gt; Repeat1 Fold10 &lt;tibble [3 × 6]&gt; &lt;tibble [0 × 1]&gt;     0
#&gt; # … with 610 more rows</code></pre>
<p>As with grid search, we can summarize the results over resamples:</p>
<pre class="r"><code>estimates &lt;- collect_metrics(search_res) %&gt;% arrange(.iter)
estimates
#&gt; # A tibble: 33 x 9
#&gt;        cost rbf_sigma num_comp .iter .metric .estimator  mean     n std_err
#&gt;       &lt;dbl&gt;     &lt;dbl&gt;    &lt;int&gt; &lt;dbl&gt; &lt;chr&gt;   &lt;chr&gt;      &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt;
#&gt;  1  0.00849  1.24e- 2       15     0 roc_auc binary     0.865    20 0.00711
#&gt;  2  0.0945   2.38e- 9       13     0 roc_auc binary     0.862    20 0.00734
#&gt;  3 13.7      3.51e- 4        5     0 roc_auc binary     0.862    20 0.00714
#&gt;  4  0.00382  5.23e- 6        3     1 roc_auc binary     0.852    20 0.00759
#&gt;  5 30.3      1.20e-10       20     2 roc_auc binary     0.865    20 0.00694
#&gt;  6  0.0210   9.96e- 1        3     3 roc_auc binary     0.856    20 0.00732
#&gt;  7  0.00168  1.67e-10       20     4 roc_auc binary     0.792    20 0.0340 
#&gt;  8  0.00100  1.27e- 9        8     5 roc_auc binary     0.792    20 0.0341 
#&gt;  9  0.350    2.28e- 6        3     6 roc_auc binary     0.852    20 0.00759
#&gt; 10  1.08     9.17e- 1       19     7 roc_auc binary     0.748    20 0.0117 
#&gt; # … with 23 more rows</code></pre>
<p>The best performance of the initial set of candidate values was <code>AUC = 0.865</code>. The best results were achieved at iteration 20 with a corresponding AUC value of 0.869. The five best results were:</p>
<pre class="r"><code>show_best(search_res)
#&gt; # A tibble: 5 x 9
#&gt;      cost rbf_sigma num_comp .iter .metric .estimator  mean     n std_err
#&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;int&gt; &lt;dbl&gt; &lt;chr&gt;   &lt;chr&gt;      &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt;
#&gt; 1 0.00972 0.0175           9    20 roc_auc binary     0.869    20 0.00754
#&gt; 2 0.00103 0.533            8     9 roc_auc binary     0.867    20 0.00835
#&gt; 3 0.00107 0.00336         20    30 roc_auc binary     0.866    20 0.00692
#&gt; 4 0.00849 0.0124          15     0 roc_auc binary     0.865    20 0.00711
#&gt; 5 8.03    0.0000424        8    22 roc_auc binary     0.865    20 0.00748</code></pre>
<p>A plot of the search can be created via:</p>
<pre class="r"><code>autoplot(search_res, type = &quot;performance&quot;)</code></pre>
<p><img src="/examples/bayesian-optimization/index_files/figure-html/bo-plot-1.png" width="672" /></p>
</div>
