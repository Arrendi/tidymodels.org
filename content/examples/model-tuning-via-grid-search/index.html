---
title: "Model Tuning via Grid Search"
tags: [tune, kernlab, grid search, classification models, model tuning]
---

<script src="/rmarkdown-libs/jquery/jquery.min.js"></script>
<script src="/rmarkdown-libs/elevate-section-attrs/elevate-section-attrs.js"></script>


<p>In addition to the <code>tidymodels</code> package, this example uses the <code>kernlab</code>, and <code>mlbench</code> packages.</p>
<p>To demonstrate model tuning, we’ll use the Ionosphere data in the <code>mlbench</code> package:</p>
<pre class="r"><code>library(tidymodels)
library(mlbench)
data(Ionosphere)</code></pre>
<p>There are 43 predictors and a factor outcome. Two of the predictors are factors (<code>V1</code> and <code>V2</code>) and the rest are numerics that have been scaled to a range of -1 to 1. Note that the two factor predictors have sparse distributions:</p>
<pre class="r"><code>table(Ionosphere$V1)</code></pre>
<pre><code>## 
##   0   1 
##  38 313</code></pre>
<pre class="r"><code>table(Ionosphere$V2)</code></pre>
<pre><code>## 
##   0 
## 351</code></pre>
<p>There’s no point of putting <code>V2</code> into any model since is is a zero-variance predictor. <code>V1</code> is not but it <em>could</em> be if the resampling process ends up sampling all of the same value. Is this an issue? It might be since the standard R formula infrastructure fails when there is only a single observed value:</p>
<pre class="r"><code>glm(Class ~ ., data = Ionosphere, family = binomial)</code></pre>
<pre><code>## Error in `contrasts&lt;-`(`*tmp*`, value = contr.funs[1 + isOF[nn]]): contrasts can be applied only to factors with 2 or more levels</code></pre>
<pre class="r"><code># Surprisingly, this doesn&#39;t help: 

glm(Class ~ . - V2, data = Ionosphere, family = binomial)</code></pre>
<pre><code>## Error in `contrasts&lt;-`(`*tmp*`, value = contr.funs[1 + isOF[nn]]): contrasts can be applied only to factors with 2 or more levels</code></pre>
<p>At a minimum, let’s get rid of the most problematic variable:</p>
<pre class="r"><code>Ionosphere &lt;- Ionosphere %&gt;% select(-V2)</code></pre>
<div id="inputs-for-the-search" class="section level2">
<h2>Inputs for the Search</h2>
<p>To demonstrate, we’ll fit a radial basis function support vector machine to these data and tune the SVM cost parameter and the <span class="math inline">\(\sigma\)</span> parameter in the kernel function:</p>
<pre class="r"><code>svm_mod &lt;-
  svm_rbf(cost = tune(), rbf_sigma = tune()) %&gt;%
  set_mode(&quot;classification&quot;) %&gt;%
  set_engine(&quot;kernlab&quot;)</code></pre>
<p>In the code below, tuning will be demonstrated using a standard R formula as well as this recipe:</p>
<pre class="r"><code>iono_rec &lt;-
  recipe(Class ~ ., data = Ionosphere)  %&gt;%
  # In case V1 is has a single value sampled
  step_zv(all_predictors()) %&gt;% 
  # convert it to a dummy variable
  step_dummy(V1) %&gt;%
  # Scale it the same as the others
  step_range(matches(&quot;V1_&quot;))</code></pre>
<p>The only other required item for tuning is a resampling strategy as defined by an <code>rsample</code> object. Let’s demonstrate using basic bootstrapping:</p>
<pre class="r"><code>set.seed(4943)
iono_rs &lt;- bootstraps(Ionosphere, times = 30)</code></pre>
</div>
<div id="optional-inputs" class="section level2">
<h2>Optional Inputs</h2>
<p>An <em>optional</em> step for model tuning is to specify which metrics should be computed using the out-of-sample predictions. For classification, the default is to calculate the log-likelihood statistic and overall accuracy. Instead of the defaults, the area under the ROC curve will be used. To do this, a <code>yardstick</code> function can be used to create a metric set:</p>
<pre class="r"><code>roc_vals &lt;- metric_set(roc_auc)</code></pre>
<p>If no grid or parameters are provided, a set of 10 are created using a space-filling design (via a Latin hypercube). A grid can be given in a data frame where the parameters are in columns and parameter combinations are in rows. Here, the default will be used.</p>
<p>Also, a control object can be passed that specifies different aspects of the search. Here, the verbose option is turned off.</p>
<pre class="r"><code>ctrl &lt;- control_grid(verbose = FALSE)</code></pre>
</div>
<div id="executing-the-grid-using-a-formula" class="section level2">
<h2>Executing the Grid Using a Formula</h2>
<p>First, the formula interface will be used:</p>
<pre class="r"><code>set.seed(35)
grid_form &lt;-
  tune_grid(
    Class ~ .,
    model = svm_mod,
    resamples = iono_rs,
    metrics = roc_vals,
    control = ctrl
  )
grid_form</code></pre>
<pre><code>## # Bootstrap sampling 
## # A tibble: 30 x 4
##    splits            id          .metrics          .notes          
##  * &lt;list&gt;            &lt;chr&gt;       &lt;list&gt;            &lt;list&gt;          
##  1 &lt;split [351/120]&gt; Bootstrap01 &lt;tibble [10 × 5]&gt; &lt;tibble [0 × 1]&gt;
##  2 &lt;split [351/130]&gt; Bootstrap02 &lt;tibble [10 × 5]&gt; &lt;tibble [0 × 1]&gt;
##  3 &lt;split [351/137]&gt; Bootstrap03 &lt;tibble [10 × 5]&gt; &lt;tibble [0 × 1]&gt;
##  4 &lt;split [351/141]&gt; Bootstrap04 &lt;tibble [10 × 5]&gt; &lt;tibble [0 × 1]&gt;
##  5 &lt;split [351/131]&gt; Bootstrap05 &lt;tibble [10 × 5]&gt; &lt;tibble [0 × 1]&gt;
##  6 &lt;split [351/131]&gt; Bootstrap06 &lt;tibble [10 × 5]&gt; &lt;tibble [0 × 1]&gt;
##  7 &lt;split [351/127]&gt; Bootstrap07 &lt;tibble [10 × 5]&gt; &lt;tibble [0 × 1]&gt;
##  8 &lt;split [351/123]&gt; Bootstrap08 &lt;tibble [10 × 5]&gt; &lt;tibble [0 × 1]&gt;
##  9 &lt;split [351/131]&gt; Bootstrap09 &lt;tibble [10 × 5]&gt; &lt;tibble [0 × 1]&gt;
## 10 &lt;split [351/117]&gt; Bootstrap10 &lt;tibble [10 × 5]&gt; &lt;tibble [0 × 1]&gt;
## # … with 20 more rows</code></pre>
<p>The <code>.metrics</code> column contains tibbles of the performance metrics for each tuning parameter combination:</p>
<pre class="r"><code>grid_form %&gt;% select(.metrics) %&gt;% slice(1) %&gt;% pull(1)</code></pre>
<pre><code>## [[1]]
## # A tibble: 10 x 5
##        cost rbf_sigma .metric .estimator .estimate
##       &lt;dbl&gt;     &lt;dbl&gt; &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;
##  1  0.00849  1.11e-10 roc_auc binary         0.890
##  2  0.176    7.28e- 8 roc_auc binary         0.903
##  3 14.9      3.93e- 4 roc_auc binary         0.913
##  4  5.51     2.10e- 3 roc_auc binary         0.937
##  5  1.87     3.53e- 7 roc_auc binary         0.909
##  6  0.00719  1.45e- 5 roc_auc binary         0.905
##  7  0.00114  8.41e- 2 roc_auc binary         0.968
##  8  0.950    1.74e- 1 roc_auc binary         0.984
##  9  0.189    3.13e- 6 roc_auc binary         0.905
## 10  0.0364   4.96e- 9 roc_auc binary         0.908</code></pre>
<p>To get the final resampling estimates, the <code>collect_metrics()</code> function can be used on the grid object:</p>
<pre class="r"><code>estimates &lt;- collect_metrics(grid_form)
estimates</code></pre>
<pre><code>## # A tibble: 10 x 7
##        cost rbf_sigma .metric .estimator  mean     n std_err
##       &lt;dbl&gt;     &lt;dbl&gt; &lt;chr&gt;   &lt;chr&gt;      &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt;
##  1  0.00114  8.41e- 2 roc_auc binary     0.969    30 0.00278
##  2  0.00719  1.45e- 5 roc_auc binary     0.917    30 0.00387
##  3  0.00849  1.11e-10 roc_auc binary     0.862    30 0.00644
##  4  0.0364   4.96e- 9 roc_auc binary     0.916    30 0.00374
##  5  0.176    7.28e- 8 roc_auc binary     0.916    30 0.00381
##  6  0.189    3.13e- 6 roc_auc binary     0.917    30 0.00389
##  7  0.950    1.74e- 1 roc_auc binary     0.979    30 0.00195
##  8  1.87     3.53e- 7 roc_auc binary     0.917    30 0.00387
##  9  5.51     2.10e- 3 roc_auc binary     0.962    30 0.00316
## 10 14.9      3.93e- 4 roc_auc binary     0.936    30 0.00391</code></pre>
<p>The best combination was:</p>
<pre class="r"><code>show_best(grid_form)</code></pre>
<pre><code>## # A tibble: 5 x 7
##       cost rbf_sigma .metric .estimator  mean     n std_err
##      &lt;dbl&gt;     &lt;dbl&gt; &lt;chr&gt;   &lt;chr&gt;      &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt;
## 1  0.950   0.174     roc_auc binary     0.979    30 0.00195
## 2  0.00114 0.0841    roc_auc binary     0.969    30 0.00278
## 3  5.51    0.00210   roc_auc binary     0.962    30 0.00316
## 4 14.9     0.000393  roc_auc binary     0.936    30 0.00391
## 5  0.00719 0.0000145 roc_auc binary     0.917    30 0.00387</code></pre>
</div>
<div id="executing-the-grid-using-a-recipe" class="section level2">
<h2>Executing the Grid Using a Recipe</h2>
<p>The same syntax is used but a recipe is passed in the first argument:</p>
<pre class="r"><code>set.seed(325)
rec_form &lt;-
  tune_grid(
    iono_rec,
    model = svm_mod,
    resamples = iono_rs,
    metrics = roc_vals,
    control = ctrl
  )
rec_form</code></pre>
<pre><code>## # Bootstrap sampling 
## # A tibble: 30 x 4
##    splits            id          .metrics          .notes          
##  * &lt;list&gt;            &lt;chr&gt;       &lt;list&gt;            &lt;list&gt;          
##  1 &lt;split [351/120]&gt; Bootstrap01 &lt;tibble [10 × 5]&gt; &lt;tibble [0 × 1]&gt;
##  2 &lt;split [351/130]&gt; Bootstrap02 &lt;tibble [10 × 5]&gt; &lt;tibble [0 × 1]&gt;
##  3 &lt;split [351/137]&gt; Bootstrap03 &lt;tibble [10 × 5]&gt; &lt;tibble [0 × 1]&gt;
##  4 &lt;split [351/141]&gt; Bootstrap04 &lt;tibble [10 × 5]&gt; &lt;tibble [0 × 1]&gt;
##  5 &lt;split [351/131]&gt; Bootstrap05 &lt;tibble [10 × 5]&gt; &lt;tibble [0 × 1]&gt;
##  6 &lt;split [351/131]&gt; Bootstrap06 &lt;tibble [10 × 5]&gt; &lt;tibble [0 × 1]&gt;
##  7 &lt;split [351/127]&gt; Bootstrap07 &lt;tibble [10 × 5]&gt; &lt;tibble [0 × 1]&gt;
##  8 &lt;split [351/123]&gt; Bootstrap08 &lt;tibble [10 × 5]&gt; &lt;tibble [0 × 1]&gt;
##  9 &lt;split [351/131]&gt; Bootstrap09 &lt;tibble [10 × 5]&gt; &lt;tibble [0 × 1]&gt;
## 10 &lt;split [351/117]&gt; Bootstrap10 &lt;tibble [10 × 5]&gt; &lt;tibble [0 × 1]&gt;
## # … with 20 more rows</code></pre>
<p>The best setting here was:</p>
<pre class="r"><code>show_best(rec_form)</code></pre>
<pre><code>## # A tibble: 5 x 7
##      cost rbf_sigma .metric .estimator  mean     n std_err
##     &lt;dbl&gt;     &lt;dbl&gt; &lt;chr&gt;   &lt;chr&gt;      &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt;
## 1 15.6    0.182     roc_auc binary     0.981    30 0.00215
## 2  0.385  0.0276    roc_auc binary     0.978    30 0.00220
## 3  0.143  0.00243   roc_auc binary     0.948    30 0.00349
## 4  0.841  0.000691  roc_auc binary     0.921    30 0.00421
## 5  0.0499 0.0000335 roc_auc binary     0.903    30 0.00463</code></pre>
</div>
