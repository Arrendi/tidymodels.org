---
title: "Classification models using a neural network"
tags: [rsample, parsnip]
categories: [model fitting]
type: learn-subsection
---



<div id="learning-objective" class="section level1">
<h1>Learning objective</h1>
<p>Train a classification model and evaluate its performance</p>
</div>
<div id="introduction" class="section level1">
<h1>Introduction</h1>
<p>This article requires that you have the following packages installed: keras and tidymodels. You will also need the python keras library installed (see <code>?keras::install_keras()</code>).</p>
<p>We can create classification models with the tidymodels package <a href="https://tidymodels.github.io/parsnip/">parsnip</a> to predict categorical quantities or class labels. Here, let’s fit a single classification model using a neural network and evaluate using a validation set. While the <a href="https://tidymodels.github.io/tune/">tune</a> package has functionality to also do this, the parsnip package is the center of attention in this article so that we can better understand its usage.</p>
</div>
<div id="fitting-a-neural-network-model" class="section level1">
<h1>Fitting a neural network model</h1>
<p>Let’s fit a model to a small, two predictor classification data set. The data are in the workflows package and have been split into training, validation, and test data sets. In this analysis, the test set is left untouched; this article tries to emulate a good data usage methodology where the test set would only be evaluated once at the end after a variety of models have been considered.</p>
<pre class="r"><code>data(bivariate)
nrow(bivariate_train)
#&gt; [1] 1009
nrow(bivariate_val)
#&gt; [1] 300</code></pre>
<p>A plot of the data shows two right-skewed predictors:</p>
<pre class="r"><code>ggplot(bivariate_train, aes(x = A, y = B, col = Class)) + 
  geom_point(alpha = .2)</code></pre>
<p><img src="figs/biv-plot-1.svg" width="576" /></p>
<p>Let’s use a single hidden layer neural network to predict the outcome. To do this, we transform the predictor columns to be more symmetric (via the <code>step_BoxCox()</code> function) and on a common scale (using <code>step_normalize()</code>). We can use recipes to do so:</p>
<pre class="r"><code>biv_rec &lt;- 
  recipe(Class ~ ., data = bivariate_train) %&gt;%
  # There are some missing values to be imputed: 
  step_BoxCox(all_predictors())%&gt;%
  step_normalize(all_predictors()) %&gt;%
  # Estimate the means and standard deviations for the columns as well as
  # the two transformation parameters: 
  prep(training = bivariate_train, retain = TRUE)

# juice() will be used to get the processed training set back

val_normalized &lt;- bake(biv_rec, new_data = bivariate_val, all_predictors())
# For when we arrive at a final model: 
test_normalized &lt;- bake(biv_rec, new_data = bivariate_test, all_predictors())</code></pre>
<p>We can use the keras package to fit a model with 5 hidden units and a 10% dropout rate, to regularize the model:</p>
<pre class="r"><code>set.seed(57974)
nnet_fit &lt;-
  mlp(epochs = 100, hidden_units = 5, dropout = 0.1) %&gt;%
  set_mode(&quot;classification&quot;) %&gt;% 
  # Also set engine-specific argument to prevent logging the results: 
  set_engine(&quot;keras&quot;, verbose = 0) %&gt;%
  fit(Class ~ ., data = juice(biv_rec))

nnet_fit
#&gt; parsnip model object
#&gt; 
#&gt; Fit time:  7.8s 
#&gt; Model
#&gt; Model: &quot;sequential&quot;
#&gt; ________________________________________________________________________________
#&gt; Layer (type)                        Output Shape                    Param #     
#&gt; ================================================================================
#&gt; dense (Dense)                       (None, 5)                       15          
#&gt; ________________________________________________________________________________
#&gt; dense_1 (Dense)                     (None, 5)                       30          
#&gt; ________________________________________________________________________________
#&gt; dropout (Dropout)                   (None, 5)                       0           
#&gt; ________________________________________________________________________________
#&gt; dense_2 (Dense)                     (None, 2)                       12          
#&gt; ================================================================================
#&gt; Total params: 57
#&gt; Trainable params: 57
#&gt; Non-trainable params: 0
#&gt; ________________________________________________________________________________</code></pre>
<div id="model-performance" class="section level2">
<h2>Model performance</h2>
<p>In parsnip, the <code>predict()</code> function can be used to characterize performance on the validation set. Since parsnip always produces tibble outputs, these can just be column bound to the original data:</p>
<pre class="r"><code>val_results &lt;- 
  bivariate_val %&gt;%
  bind_cols(
    predict(nnet_fit, new_data = val_normalized),
    predict(nnet_fit, new_data = val_normalized, type = &quot;prob&quot;)
  )
val_results %&gt;% slice(1:5)
#&gt; # A tibble: 5 x 6
#&gt;       A     B Class .pred_class .pred_One .pred_Two
#&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;fct&gt; &lt;fct&gt;           &lt;dbl&gt;     &lt;dbl&gt;
#&gt; 1 1061.  74.5 One   Two             0.475    0.525 
#&gt; 2 1241.  83.4 One   Two             0.486    0.514 
#&gt; 3  939.  71.9 One   One             0.636    0.364 
#&gt; 4  813.  77.1 One   One             0.923    0.0769
#&gt; 5 1706.  92.8 Two   Two             0.359    0.641

val_results %&gt;% roc_auc(truth = Class, .pred_One)
#&gt; # A tibble: 1 x 3
#&gt;   .metric .estimator .estimate
#&gt;   &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;
#&gt; 1 roc_auc binary         0.815

val_results %&gt;% accuracy(truth = Class, .pred_class)
#&gt; # A tibble: 1 x 3
#&gt;   .metric  .estimator .estimate
#&gt;   &lt;chr&gt;    &lt;chr&gt;          &lt;dbl&gt;
#&gt; 1 accuracy binary         0.733

val_results %&gt;% conf_mat(truth = Class, .pred_class)
#&gt;           Truth
#&gt; Prediction One Two
#&gt;        One 150  28
#&gt;        Two  52  70</code></pre>
<p>Let’s also create a grid to get a visual sense of the class boundary for the validation set.</p>
<pre class="r"><code>a_rng &lt;- range(bivariate_train$A)
b_rng &lt;- range(bivariate_train$B)
x_grid &lt;-
  expand.grid(A = seq(a_rng[1], a_rng[2], length.out = 100),
              B = seq(b_rng[1], b_rng[2], length.out = 100))
x_grid_trans &lt;- bake(biv_rec, x_grid)

# Make predictions using the transformed predictors but 
# attach them to the predictors in the original units: 
x_grid &lt;- 
  x_grid %&gt;% 
  bind_cols(predict(nnet_fit, x_grid_trans, type = &quot;prob&quot;))

ggplot(x_grid, aes(x = A, y = B)) + 
  geom_contour(aes(z = .pred_One), breaks = .5, col = &quot;black&quot;) + 
  geom_point(data = bivariate_val, aes(col = Class), alpha = 0.3)</code></pre>
<p><img src="figs/biv-boundary-1.svg" width="576" /></p>
</div>
</div>
<div id="session-information" class="section level1">
<h1>Session information</h1>
<pre><code>#&gt; ─ Session info ───────────────────────────────────────────────────────────────
#&gt;  setting  value                       
#&gt;  version  R version 3.6.2 (2019-12-12)
#&gt;  os       macOS Mojave 10.14.6        
#&gt;  system   x86_64, darwin15.6.0        
#&gt;  ui       X11                         
#&gt;  language (EN)                        
#&gt;  collate  en_US.UTF-8                 
#&gt;  ctype    en_US.UTF-8                 
#&gt;  tz       America/Denver              
#&gt;  date     2020-04-01                  
#&gt; 
#&gt; ─ Packages ───────────────────────────────────────────────────────────────────
#&gt;  package    * version      date       lib source                               
#&gt;  broom      * 0.5.5        2020-02-29 [1] CRAN (R 3.6.0)                       
#&gt;  dials      * 0.0.4.9000   2020-03-20 [1] local                                
#&gt;  dplyr      * 0.8.5        2020-03-07 [1] CRAN (R 3.6.0)                       
#&gt;  ggplot2    * 3.3.0        2020-03-05 [1] CRAN (R 3.6.0)                       
#&gt;  infer      * 0.5.1        2019-11-19 [1] CRAN (R 3.6.0)                       
#&gt;  keras        2.2.5.0      2019-10-08 [1] CRAN (R 3.6.0)                       
#&gt;  parsnip    * 0.0.5        2020-01-07 [1] CRAN (R 3.6.2)                       
#&gt;  purrr      * 0.3.3        2019-10-18 [1] CRAN (R 3.6.0)                       
#&gt;  recipes    * 0.1.10       2020-03-18 [1] CRAN (R 3.6.0)                       
#&gt;  rlang        0.4.5.9000   2020-03-20 [1] Github (r-lib/rlang@a90b04b)         
#&gt;  rsample    * 0.0.5        2019-07-12 [1] CRAN (R 3.6.0)                       
#&gt;  tibble     * 2.99.99.9014 2020-03-26 [1] Github (tidyverse/tibble@2448bb0)    
#&gt;  tidymodels * 0.1.0        2020-02-16 [1] CRAN (R 3.6.0)                       
#&gt;  tune       * 0.0.1.9000   2020-03-23 [1] local                                
#&gt;  workflows  * 0.1.1.9000   2020-03-20 [1] Github (tidymodels/workflows@e995c18)
#&gt;  yardstick  * 0.0.5.9000   2020-03-20 [1] Github (tidymodels/yardstick@6a9a69a)
#&gt; 
#&gt; [1] /Library/Frameworks/R.framework/Versions/3.6/Resources/library</code></pre>
</div>
