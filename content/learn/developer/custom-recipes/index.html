---
title: "Creating Custom Recipe Step Functions"
tags: [recipes]
categories: []
type: learn-subsection
---

<script src="/rmarkdown-libs/header-attrs/header-attrs.js"></script>


<div id="introduction" class="section level1">
<h1>Introduction</h1>
<p>There are a large number of existing recipe steps in packages like recipes, themis and others. A full list of steps in CRAN packages cna be found here. However, you might need to define your own operations; this page describes how to do that. If you are looking for good examples of existing steps, I would suggest looking at the code for <a href="https://github.com/tidymodels/recipes/blob/master/R/center.R">centering</a> or <a href="https://github.com/tidymodels/recipes/blob/master/R/pca.R">PCA</a> to start.</p>
<p>For checks operations (e.g. <code>check_class()</code>), the process is very similar. Notes on this are given at the end of this document.</p>
<p>The general process to follow is to</p>
<ol style="list-style-type: decimal">
<li><p>Define a step constructor function.</p></li>
<li><p>Create the minimal S3 methods for <code>prep()</code>, <code>bake()</code>, and <code>print()</code>.</p></li>
<li><p>Optionally add some extra methods to work with other tidymodels packages, such as <code>tunable()</code> and <code>tidy()</code>.</p></li>
</ol>
<p>As an example, a step for converting data into percentiles will be used.</p>
</div>
<div id="a-new-step-definition" class="section level1">
<h1>A new step definition</h1>
<p>As an example, let’s create a step that replaces the value of a variable with its percentile from the training set. The date that I’ll use is from the recipes package:</p>
<pre class="r"><code>library(modeldata)
data(biomass)
str(biomass)
#&gt; &#39;data.frame&#39;:    536 obs. of  8 variables:
#&gt;  $ sample  : chr  &quot;Akhrot Shell&quot; &quot;Alabama Oak Wood Waste&quot; &quot;Alder&quot; &quot;Alfalfa&quot; ...
#&gt;  $ dataset : chr  &quot;Training&quot; &quot;Training&quot; &quot;Training&quot; &quot;Training&quot; ...
#&gt;  $ carbon  : num  49.8 49.5 47.8 45.1 46.8 ...
#&gt;  $ hydrogen: num  5.64 5.7 5.8 4.97 5.4 5.75 5.99 5.7 5.5 5.9 ...
#&gt;  $ oxygen  : num  42.9 41.3 46.2 35.6 40.7 ...
#&gt;  $ nitrogen: num  0.41 0.2 0.11 3.3 1 2.04 2.68 1.7 0.8 1.2 ...
#&gt;  $ sulfur  : num  0 0 0.02 0.16 0.02 0.1 0.2 0.2 0 0.1 ...
#&gt;  $ HHV     : num  20 19.2 18.3 18.2 18.4 ...

biomass_tr &lt;- biomass[biomass$dataset == &quot;Training&quot;,]
biomass_te &lt;- biomass[biomass$dataset == &quot;Testing&quot;,]</code></pre>
<p>To illustrate the transformation with the <code>carbon</code> variable, the training set distribution of that variables is shown below with a vertical line for the first value of the test set.</p>
<pre class="r"><code>library(ggplot2)
theme_set(theme_bw())
ggplot(biomass_tr, aes(x = carbon)) + 
  geom_histogram(binwidth = 5, col = &quot;blue&quot;, fill = &quot;blue&quot;, alpha = .5) + 
  geom_vline(xintercept = biomass_te$carbon[1], lty = 2)</code></pre>
<p><img src="/learn/developer/custom-recipes/index_files/figure-html/carbon_dist-1.png" width="100%" /></p>
<p>Based on the training set, 42.1% of the data are less than a value of 46.35. There are some applications where it might be advantageous to represent the predictor values as percentiles rather than their original values.</p>
<p>Our new step will do this computation for any numeric variables of interest. We will call this <code>step_percentile()</code>. The code below is designed for illustration and not speed or best practices. I’ve left out a lot of error trapping that we would want in a real implementation.</p>
</div>
<div id="create-the-initial-function" class="section level1">
<h1>Create the initial function</h1>
<p>To start, there is a <em>user-facing</em> function. Let’s call that <code>step_percentile()</code>. This is just a simple wrapper around a <em>constructor function</em>, which defines the rules for any step object that defines a percentile transformation. We’l call this constructor <code>step_percentile_new()</code>.</p>
<p><code>step_percentile()</code> takes the same arguments as your function and simply adds it to a new recipe. The <code>...</code> signifies the variable selectors that can be used<a href="#fn1" class="footnote-ref" id="fnref1"><sup>1</sup></a>.</p>
<pre class="r"><code>step_percentile &lt;- function(
  recipe, 
  ..., 
  role = NA, 
  trained = FALSE, 
  ref_dist = NULL,
  options = list(probs = (0:100)/100, names = TRUE),
  skip = FALSE,
  id = rand_id(&quot;percentile&quot;)
  ) {

  ## The variable selectors are not immediately evaluated by using
  ##  the `quos()` function in `rlang`. `ellipse_check()` captures 
  ##  the values and also checks to make sure that they are not empty.  
  terms &lt;- ellipse_check(...) 

  add_step(
    recipe, 
    step_percentile_new(
      terms = terms, 
      trained = trained,
      role = role, 
      ref_dist = ref_dist,
      options = options,
      skip = skip,
      id = id
    )
  )
}</code></pre>
<p>You should always keep the first four arguments (<code>recipe</code> though <code>trained</code>) the same as listed above. Some notes:</p>
<ul>
<li>the <code>role</code> argument is used when you either 1) create new variables and want their role to be pre-set or 2) replace the existing variables with new values. The latter is what we will be doing and using <code>role = NA</code> will leave the existing role intact.</li>
<li><code>trained</code> is set by the package when the estimation step has been run. You should default your function definition’s argument to <code>FALSE</code>.</li>
<li><code>skip</code> is a logical. Whenever a recipe is prepped, each step is trained and then baked. However, there are some steps that should not be applied when a call to <code>bake()</code> is used. For example, if a step is applied to the variables with roles of “outcomes”, these data would not be available for new samples.</li>
<li><code>id</code> is a character string that can be used to identify steps in package code. <code>rand_id()</code> will create an ID that has the prefix and a random character sequence.</li>
</ul>
<p>In order to calculate the percentile, the training data for the relevant columns will need to be saved. This data will be saved in the <code>ref_dist</code> object. <code>approx()</code> would be used when you want to save a grid of pre-computed percentiles from the training set and use these to estimate the percentile for a new data point.</p>
<p>We will use the <code>stats::quantile()</code> to compute the grid. However, we might also want to have control over the granularity of this grid, so the <code>options</code> argument will be used to define how that calculations is done. We could just use the ellipses (aka <code>...</code>) so that any options passed to <code>step_percentile()</code> that are not one of its arguments will then be passed to <code>stats::quantile()</code>. We recommend making a separate list object with the options and use these inside the function.</p>
<p>It is also important to consider if there are any <em>main arguments</em> to the step. For example, for spline-related steps such as <code>step_ns()</code>, users would typically want to adjust the argument for the degrees of freedom in the spline (e.g. <code>splines::ns(x, df)</code>). Rather letting users add <code>df</code> to the <code>options</code> argument:</p>
<ul>
<li><p>Allow the important arguments to be main arguments to the step function.</p></li>
<li><p>Follow the tidymodels <a href="https://tidymodels.github.io/model-implementation-principles/standardized-argument-names.html">conventions for naming arguments</a>. Whenever possible, avoid jargon and keep common argument names.</p></li>
</ul>
<p>There are benefits to following these principles (as shown below).</p>
<p>Now, the constructor function can be created.</p>
</div>
<div id="initialization-of-a-new-step_percentile-objects" class="section level1">
<h1>Initialization of a new step_percentile objects</h1>
<p>The function cascade is:</p>
<pre><code>step_percentile() calls recipes::add_step()
└──&gt; recipes::add_step() calls step_percentile_new()
    └──&gt; step_percentile_new() calls recipes::step()</code></pre>
<p><code>step()</code> is a general constuctor for recipes that mainly makes sure that the resulting step object is a list with an appropriate S3 class structure. Using <code>subclass = "percentile"</code> will set the class of new objects to <code>"step_percentile()"</code>.</p>
<pre class="r"><code>step_percentile_new &lt;- 
  function(terms, role, trained, ref_dist, options, skip, id) {
    step(
      subclass = &quot;percentile&quot;, 
      terms = terms,
      role = role,
      trained = trained,
      ref_dist = ref_dist,
      options = options,
      skip = skip,
      id = id
    )
  }</code></pre>
<p>This constructor function should have no default argument values. Default should be set in the user-facing step object.</p>
</div>
<div id="define-the-estimation-procedure" class="section level1">
<h1>Define the estimation procedure</h1>
<p>You will need to create a new <code>prep()</code> method for your step’s class. To do this, three arguments that the method should have:</p>
<pre class="r"><code>function(x, training, info = NULL)</code></pre>
<p>where</p>
<ul>
<li><code>x</code> will be the <code>step_percentile</code> object</li>
<li><code>training</code> will be a <em>tibble</em> that has the training set data</li>
<li><code>info</code> will also be a tibble that has information on the current set of data available. This information is updated as each step is evaluated by its specific <code>prep()</code> method so it may not have the variables from the original data. The columns in this tibble are <code>variable</code> (the variable name), <code>type</code> (currently either “numeric” or “nominal”), <code>role</code> (defining the variable’s role), and <code>source</code> (either “original” or “derived” depending on where it originated).</li>
</ul>
<p>You can define other options.</p>
<p>The first thing that you might want to do in the <code>prep()</code> function is to translate the specification listed in the <code>terms</code> argument to column names in the current data. There is an internal function called <code>terms_select()</code> that can be used to obtain this.</p>
<pre class="r"><code>prep.step_percentile &lt;- function(x, training, info = NULL, ...) {
  col_names &lt;- terms_select(terms = x$terms, info = info) 
}</code></pre>
<p>After this function call, it is a good idea to check that the selected columns have the appropriate type (e.g. numeric for this example). See <code>recipes::check_type()</code> to do this for basic types.</p>
<p>Once we have this, we can save the approximation grid. For the grid, we will use a helper function that enables us to run <code>rlang::exec()</code> to splice in any extra arguments contained in the <code>options</code> list to the call to <code>quantile()</code>:</p>
<pre class="r"><code>get_train_pctl &lt;- function(x, args = NULL) {
  res &lt;- rlang::exec(&quot;quantile&quot;, x = x, !!!args)
  # Remove duplicate percentile values
  res[!duplicated(res)]
}

# For example:
get_train_pctl(biomass_tr$carbon, list(probs = 0:1))
#&gt;   0% 100% 
#&gt; 14.6 97.2
get_train_pctl(biomass_tr$carbon)
#&gt;   0%  25%  50%  75% 100% 
#&gt; 14.6 44.7 47.1 49.7 97.2</code></pre>
<p>Now, the <code>prep()</code> method can be created:</p>
<pre class="r"><code>prep.step_percentile &lt;- function(x, training, info = NULL, ...) {
  col_names &lt;- terms_select(terms = x$terms, info = info) 
  ## You can add error trapping for non-numeric data here and so on. 
  
  ## We&#39;ll use the names later so
  if (x$options$names == FALSE) {
    rlang::abort(&quot;`names` should be set to TRUE&quot;)
  }
  
  if (!any(names(x$options) == &quot;probs&quot;)) {
    x$options$probs &lt;- (0:100)/100
  } else {
    x$options$probs &lt;- sort(unique(x$options$probs))
  }
  
  # Compute percentile grid
  ref_dist &lt;- purrr::map(training[, col_names],  get_train_pctl, args = x$options)

  ## Use the constructor function to return the updated object. 
  ## Note that `trained` is now set to TRUE
  
  step_percentile_new(
    terms = x$terms, 
    trained = TRUE,
    role = x$role, 
    ref_dist = ref_dist,
    options = x$options,
    skip = x$skip,
    id = x$id
  )
}</code></pre>
<p>We suggest favoring <code>rlang::abort()</code> and <code>rlang::warn()</code> over <code>stop()</code> and <code>warning()</code>. The former can be used for better traceback results.</p>
</div>
<div id="create-the-bake-method" class="section level1">
<h1>Create the <code>bake</code> method</h1>
<p>Remember that the <code>prep()</code> function does not <em>apply</em> the step to the data; it only estimates any required values such as <code>ref_dist</code>. We will need to create a new method for our <code>step_percentile()</code> class. The minimum arguments for this are</p>
<pre class="r"><code>function(object, new_data, ...)</code></pre>
<p>where <code>object</code> is the updated step function that has been through the corresponding <code>prep()</code> code and <code>new_data</code> is a tibble of data to be processed.</p>
<p>Here is the code to convert the new data to percentiles. The input data (<code>x</code> below) comes in as a numeric vector and the output is a vector if approximate percentiles:</p>
<pre class="r"><code>pctl_by_approx &lt;- function(x, ref) {
  # In case duplicates were removed, get the percentiles from
  # the names of the reference object
  grid &lt;- as.numeric(gsub(&quot;%$&quot;, &quot;&quot;, names(ref))) 
  approx(x = ref, y = grid, xout = x)$y/100
}</code></pre>
<p>These computations are done column-wise using <code>purrr::map2_dfc()</code> to modify the new data in-place:</p>
<pre class="r"><code>bake.step_percentile &lt;- function(object, new_data, ...) {
  ## For illustration (and not speed), we will loop through the affected variables
  ## and do the computations
  vars &lt;- names(object$ref_dist)
  
  new_data[, vars] &lt;-
    purrr::map2_dfc(new_data[, vars], object$ref_dist, pctl_by_approx)
  
  ## Always convert to tibbles on the way out
  tibble::as_tibble(new_data)
}</code></pre>
</div>
<div id="running-the-example" class="section level1">
<h1>Running the example</h1>
<p>Let’s use the example data to make sure that it works:</p>
<pre class="r"><code>rec_obj &lt;- 
  recipe(HHV ~ ., data = biomass_tr) %&gt;%
  step_percentile(ends_with(&quot;gen&quot;)) %&gt;%
  prep(training = biomass_tr)

biomass_te %&gt;% select(ends_with(&quot;gen&quot;)) %&gt;% slice(1:2)
#&gt;   hydrogen oxygen nitrogen
#&gt; 1     5.67   47.2     0.30
#&gt; 2     5.50   48.1     2.85
bake(rec_obj, biomass_te %&gt;% slice(1:2), ends_with(&quot;gen&quot;))
#&gt; # A tibble: 2 x 3
#&gt;   hydrogen oxygen nitrogen
#&gt;      &lt;dbl&gt;  &lt;dbl&gt;    &lt;dbl&gt;
#&gt; 1     0.45  0.903    0.21 
#&gt; 2     0.38  0.922    0.928

# Checking to get approximate result: 
mean(biomass_tr$hydrogen &lt;= biomass_te$hydrogen[1])
#&gt; [1] 0.452
mean(biomass_tr$oxygen   &lt;= biomass_te$oxygen[1])
#&gt; [1] 0.901</code></pre>
<p>The plot below shows how the original hydrogen percentiles line up with the estimated values:</p>
<pre class="r"><code>hydrogen_values &lt;- 
  bake(rec_obj, biomass_te, hydrogen) %&gt;% 
  bind_cols(biomass_te %&gt;% select(original = hydrogen))

ggplot(biomass_tr, aes(x = hydrogen)) + 
  # Plot the empirical distribution function of the 
  # hydrogen training set values as a black line
  stat_ecdf() + 
  # Overlay the estimated percentiles for the new data: 
  geom_point(data = hydrogen_values, 
             aes(x = original, y = hydrogen), 
             col = &quot;red&quot;, alpha = .5, cex = 2) + 
  labs(x = &quot;New Hydrogen Values&quot;, y = &quot;Percentile Based on Training Set&quot;)</code></pre>
<p><img src="/learn/developer/custom-recipes/index_files/figure-html/cdf_plot-1.png" width="672" /></p>
<p>These line up very nicely.</p>
</div>
<div id="custom-check-operations" class="section level1">
<h1>Custom check operations</h1>
<p>The process here is exactly the same as steps; the internal functions have a similar naming convention:</p>
<ul>
<li><code>add_check()</code> instead of <code>add_step()</code></li>
<li><code>check()</code> instead of <code>step()</code>, and so on.</li>
</ul>
<p>It is strongly recommended that:</p>
<ol style="list-style-type: decimal">
<li>The operations start with <code>check_</code> (i.e. <code>check_range()</code> and <code>check_range_new()</code>)</li>
<li>The check uses <code>rlang::abort(paste0(...))</code> when the conditions are not met</li>
<li>The original data are returned (unaltered) by the check when the conditions are satisfied.</li>
</ol>
</div>
<div id="other-step-related-methods" class="section level1">
<h1>Other step-related methods</h1>
<p>There are a few other S3 methods that can be created for your step function. They are not required unless you plan on using your step in the broader tidymodels package set.</p>
<div id="a-print-method" class="section level2">
<h2>A print method</h2>
<p>Printing <code>rec_obj</code> is a bit ugly; since there is no print method for <code>step_percentile()</code> it prints it as a list of (potentially large) objects. recipes contains a helper function called <code>printer()</code> that should work for most cases. It requires the the names of the selected columns that are resolved after <code>prep()</code> has been run as well as the original terms specification. For the former, our step object is structured so that the list object <code>ref_dist</code> has the names of the selected variables:</p>
<pre class="r"><code>print.step_percentile &lt;-
  function(x, width = max(20, options()$width - 35), ...) {
    cat(&quot;Percentile transformation on &quot;, sep = &quot;&quot;)
    printer(
      # Names before prep (could be selectors)
      untr_obj = x$terms,
      # Names after prep:
      tr_obj = names(x$ref_dist),
      # Has it been prepped? 
      trained = x$trained,
      # An estimate of how many characters to print on a line: 
      width = width
    )
    invisible(x)
  }

# Results before `prep()`:
recipe(HHV ~ ., data = biomass_tr) %&gt;%
  step_percentile(ends_with(&quot;gen&quot;))
#&gt; Data Recipe
#&gt; 
#&gt; Inputs:
#&gt; 
#&gt;       role #variables
#&gt;    outcome          1
#&gt;  predictor          7
#&gt; 
#&gt; Operations:
#&gt; 
#&gt; Percentile transformation on ends_with, gen

# Results after `prep()`: 
rec_obj
#&gt; Data Recipe
#&gt; 
#&gt; Inputs:
#&gt; 
#&gt;       role #variables
#&gt;    outcome          1
#&gt;  predictor          7
#&gt; 
#&gt; Training data contained 456 data points and no missing data.
#&gt; 
#&gt; Operations:
#&gt; 
#&gt; Percentile transformation on hydrogen, oxygen, nitrogen [trained]</code></pre>
</div>
</div>
<div id="a-tidy-method" class="section level1">
<h1>A tidy method</h1>
<p>The <code>broom::tidy()</code> method is means to return information about the step in a usable format. For our step, it would be helpful to know the reference values.</p>
<p>When the recipe has been prepped, those data are in the list <code>ref_dist</code>. A small function can be used to reformat that data into a tibble. It is customary to make the main return values be named <code>value</code>:</p>
<pre class="r"><code>format_pctl &lt;- function(x) {
  tibble::tibble(
    value = unname(x),
    percentile = as.numeric(gsub(&quot;%$&quot;, &quot;&quot;, names(x))) 
  )
}

# For example: 
pctl_step_object &lt;- rec_obj$steps[[1]]
pctl_step_object
#&gt; Percentile transformation on hydrogen, oxygen, nitrogen [trained]
format_pctl(pctl_step_object$ref_dist[[&quot;hydrogen&quot;]])
#&gt; # A tibble: 87 x 2
#&gt;    value percentile
#&gt;    &lt;dbl&gt;      &lt;dbl&gt;
#&gt;  1 0.03           0
#&gt;  2 0.934          1
#&gt;  3 1.60           2
#&gt;  4 2.07           3
#&gt;  5 2.45           4
#&gt;  6 2.74           5
#&gt;  7 3.15           6
#&gt;  8 3.49           7
#&gt;  9 3.71           8
#&gt; 10 3.99           9
#&gt; # … with 77 more rows</code></pre>
<p>The tidy method could return these values for each selected column. Before prep, missing values can be used as placeholders.</p>
<pre class="r"><code>tidy.step_percentile &lt;- function(x, ...) {
  if (is_trained(x)) {
    res &lt;- map_dfr(x$ref_dist, format_pctl, .id = &quot;term&quot;)
  }
  else {
    term_names &lt;- sel2char(x$terms)
    res &lt;-
      tibble(
        terms = term_names,
        value = rlang::na_dbl,
        percentile = rlang::na_dbl
      )
  }
  # Always return the step id: 
  res$id &lt;- x$id
  res
}

tidy(rec_obj, number = 1)
#&gt; # A tibble: 274 x 4
#&gt;    term     value percentile id              
#&gt;    &lt;chr&gt;    &lt;dbl&gt;      &lt;dbl&gt; &lt;chr&gt;           
#&gt;  1 hydrogen 0.03           0 percentile_2uTCh
#&gt;  2 hydrogen 0.934          1 percentile_2uTCh
#&gt;  3 hydrogen 1.60           2 percentile_2uTCh
#&gt;  4 hydrogen 2.07           3 percentile_2uTCh
#&gt;  5 hydrogen 2.45           4 percentile_2uTCh
#&gt;  6 hydrogen 2.74           5 percentile_2uTCh
#&gt;  7 hydrogen 3.15           6 percentile_2uTCh
#&gt;  8 hydrogen 3.49           7 percentile_2uTCh
#&gt;  9 hydrogen 3.71           8 percentile_2uTCh
#&gt; 10 hydrogen 3.99           9 percentile_2uTCh
#&gt; # … with 264 more rows</code></pre>
</div>
<div id="s3-methods-for-tuning-parameters" class="section level1">
<h1>S3 methods for tuning parameters</h1>
<p>The tune package can be used to find reasonable values of step arguments by model tuning. There are some S3 methods that are useful to define for your step. The percentile example doesn’t really have any tunable parameters, so we will demonstrate using <code>step_poly()</code>, which returns a polynomial expansion of selected columns. Its function definition has the arguments:</p>
<pre class="r"><code>args(step_poly)
#&gt; function (recipe, ..., role = &quot;predictor&quot;, trained = FALSE, objects = NULL, 
#&gt;     degree = 2, options = list(), skip = FALSE, id = rand_id(&quot;poly&quot;)) 
#&gt; NULL</code></pre>
<p><code>degree</code> is the tunable argument.</p>
<p>To work with tune it is <em>helpful</em> (but not required) to use an S3 method called <code>tunable()</code> to define which arguments should be tuned and how values of those arguments should be generated.</p>
<p><code>tunable()</code> takes the step object as its argument and returns a tibble with columns:</p>
<ul>
<li><p><code>name</code>: The name of the argument.</p></li>
<li><p><code>call_info</code>: A list that describes how to call a function that returns a dials parameter object.</p></li>
<li><p><code>source</code>: A character string that indicates where the tuning value comes from (i.e., a model, a recipe etc.). Here, it is just <code>"recipe"</code>.</p></li>
<li><p><code>component</code>: A character string with more information about the source. For recipes, this is just the name of the step (e.g. <code>"step_poly"</code>).</p></li>
<li><p><code>component_id</code>: A character string to indicate where a unique identifier is for the object. For recipes, this is just the <code>id</code> value of the step object.</p></li>
</ul>
<p>The main piece of information that requires some detail is <code>call_info</code>. This is a list column in the tibble. Each element of the list is a list that describes the package and function that can be used to create a dials parameter object.</p>
<p>For example, for a nearest-neighbors <code>neighbors</code> parameter, this value is just:</p>
<pre class="r"><code>info &lt;- list(pkg = &quot;dials&quot;, fun = &quot;neighbors&quot;)

# FYI: how it is used under-the-hood: 
new_param_call &lt;- rlang::call2(.fn = info$fun, .ns = info$pkg)
rlang::eval_tidy(new_param_call)
#&gt; # Nearest Neighbors  (quantitative)
#&gt; Range: [1, 10]</code></pre>
<p>For <code>step_poly()</code>, a dials object is needed that returns an integer that is the number of new columns to create. It turns out that there are a few different types of tuning parameters related to degree:</p>
<pre class="r"><code>&gt; lsf.str(&quot;package:dials&quot;, pattern = &quot;degree&quot;)
degree : function (range = c(1, 3), trans = NULL)  
degree_int : function (range = c(1L, 3L), trans = NULL)  
prod_degree : function (range = c(1L, 2L), trans = NULL)  
spline_degree : function (range = c(3L, 10L), trans = NULL)  </code></pre>
<p>Looking at the <code>range</code> values, some return doubles and others return integers. For our problem, <code>degree_int()</code> would be a good choice.</p>
<p>For <code>step_poly()</code> the <code>tunable()</code> S3 method could be:</p>
<pre class="r"><code>tunable.step_poly &lt;- function (x, ...) {
  tibble::tibble(
    name = c(&quot;degree&quot;),
    call_info = list(list(pkg = &quot;dials&quot;, fun = &quot;degree_int&quot;)),
    source = &quot;recipe&quot;,
    component = &quot;step_poly&quot;,
    component_id = x$id
  )
}</code></pre>
</div>
<div id="session-information" class="section level1">
<h1>Session information</h1>
<pre><code>#&gt; ─ Session info ───────────────────────────────────────────────────────────────────────────────────
#&gt;  setting  value                       
#&gt;  version  R version 3.6.1 (2019-07-05)
#&gt;  os       macOS Mojave 10.14.6        
#&gt;  system   x86_64, darwin15.6.0        
#&gt;  ui       X11                         
#&gt;  language (EN)                        
#&gt;  collate  en_US.UTF-8                 
#&gt;  ctype    en_US.UTF-8                 
#&gt;  tz       America/New_York            
#&gt;  date     2020-03-26                  
#&gt; 
#&gt; ─ Packages ───────────────────────────────────────────────────────────────────────────────────────
#&gt;  package    * version    date       lib source                             
#&gt;  broom      * 0.5.4      2020-01-27 [1] CRAN (R 3.6.0)                     
#&gt;  dials      * 0.0.4.9000 2020-03-21 [1] local                              
#&gt;  dplyr      * 0.8.5      2020-03-07 [1] CRAN (R 3.6.0)                     
#&gt;  ggplot2    * 3.3.0      2020-03-05 [1] CRAN (R 3.6.0)                     
#&gt;  modeldata  * 0.0.1      2019-12-06 [1] CRAN (R 3.6.0)                     
#&gt;  parsnip    * 0.0.5.9000 2020-03-26 [1] local                              
#&gt;  purrr      * 0.3.3      2019-10-18 [1] CRAN (R 3.6.0)                     
#&gt;  recipes    * 0.1.10     2020-03-18 [1] CRAN (R 3.6.1)                     
#&gt;  rlang        0.4.5.9000 2020-03-21 [1] Github (r-lib/rlang@a90b04b)       
#&gt;  rsample    * 0.0.5.9000 2020-03-23 [1] Github (tidymodels/rsample@4fdbd6c)
#&gt;  tibble     * 2.1.3      2019-06-06 [1] CRAN (R 3.6.0)                     
#&gt;  tidymodels * 0.1.0      2020-02-16 [1] CRAN (R 3.6.0)                     
#&gt;  tune       * 0.0.1.9000 2020-03-21 [1] Github (tidymodels/tune@6694258)   
#&gt;  workflows  * 0.1.0      2019-12-30 [1] CRAN (R 3.6.1)                     
#&gt;  yardstick  * 0.0.5      2020-01-23 [1] CRAN (R 3.6.0)                     
#&gt; 
#&gt; [1] /Library/Frameworks/R.framework/Versions/3.6/Resources/library</code></pre>
</div>
<div class="footnotes">
<hr />
<ol>
<li id="fn1"><p>Towards the end of 2020, recipes will make the change to move to the tidyverse’s new selection style that <em>does not</em> use <code>...</code> to capture the selectors. See the <a href="https://principles.tidyverse.org/dots-data.html">tidyverse principles page</a> for a discussion.<a href="#fnref1" class="footnote-back">↩︎</a></p></li>
</ol>
</div>
