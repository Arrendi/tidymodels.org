---
title: "Time Series Analysis Example"
tags: [rsample]
---

<script src="/rmarkdown-libs/header-attrs/header-attrs.js"></script>


<p>This article requires that you have the following packages installed: forecast, sweep, tidymodels, timetk, and zoo.</p>
<div id="introduction" class="section level1">
<h1>Introduction</h1>
<p>“<a href="http://www.business-science.io/code-tools/2017/10/25/demo_week_sweep.html">Demo Week: Tidy Forecasting with sweep</a>” is an excellent article that uses tidy methods with time series. This article uses their analysis with rsample to get performance estimates for future observations using <a href="https://robjhyndman.com/hyndsight/crossvalidation/">rolling forecast origin resampling</a>.</p>
</div>
<div id="example-data" class="section level1">
<h1>Example data</h1>
<p>The data are sales of alcoholic beverages originally from <a href="https://fred.stlouisfed.org/series/S4248SM144NCEN">the Federal Reserve Bank of St. Louis website</a>.</p>
<pre class="r"><code>library(tidymodels)
library(modeldata)
data(&quot;drinks&quot;)
str(drinks, give.att = FALSE)
#&gt; Classes &#39;tbl_df&#39;, &#39;tbl&#39; and &#39;data.frame&#39;:    309 obs. of  2 variables:
#&gt;  $ date          : Date, format: &quot;1992-01-01&quot; &quot;1992-02-01&quot; ...
#&gt;  $ S4248SM144NCEN: num  3459 3458 4002 4564 4221 ...</code></pre>
<p>Each row is a month of sales (in millions of US dollars).</p>
</div>
<div id="time-series-resampling" class="section level1">
<h1>Time series resampling</h1>
<p>Suppose that predictions for one year ahead were needed and the model should use the most recent data from the last 20 years. To setup this resampling scheme:</p>
<pre class="r"><code>roll_rs &lt;- rolling_origin(
  drinks, 
  initial = 12 * 20, 
  assess = 12,
  cumulative = FALSE
  )
nrow(roll_rs)
#&gt; [1] 58
roll_rs
#&gt; # Rolling origin forecast resampling 
#&gt; # A tibble: 58 x 2
#&gt;    splits           id     
#&gt;    &lt;list&gt;           &lt;chr&gt;  
#&gt;  1 &lt;split [240/12]&gt; Slice01
#&gt;  2 &lt;split [240/12]&gt; Slice02
#&gt;  3 &lt;split [240/12]&gt; Slice03
#&gt;  4 &lt;split [240/12]&gt; Slice04
#&gt;  5 &lt;split [240/12]&gt; Slice05
#&gt;  6 &lt;split [240/12]&gt; Slice06
#&gt;  7 &lt;split [240/12]&gt; Slice07
#&gt;  8 &lt;split [240/12]&gt; Slice08
#&gt;  9 &lt;split [240/12]&gt; Slice09
#&gt; 10 &lt;split [240/12]&gt; Slice10
#&gt; # … with 48 more rows</code></pre>
<p>Each <code>split</code> element contains the information about that resample:</p>
<pre class="r"><code>roll_rs$splits[[1]]
#&gt; &lt;Training/Validation/Total&gt;
#&gt; &lt;240/12/309&gt;</code></pre>
<p>For plotting, let’s index each split by the first day of the assessment set:</p>
<pre class="r"><code>get_date &lt;- function(x) {
  min(assessment(x)$date)
}

start_date &lt;- map(roll_rs$splits, get_date)
roll_rs$start_date &lt;- do.call(&quot;c&quot;, start_date)
head(roll_rs$start_date)
#&gt; [1] &quot;2012-01-01&quot; &quot;2012-02-01&quot; &quot;2012-03-01&quot; &quot;2012-04-01&quot; &quot;2012-05-01&quot;
#&gt; [6] &quot;2012-06-01&quot;</code></pre>
<p>This resampling scheme has 58 splits of the data so that there will be 58 ARIMA models that are fit. To create the models, the <code>auto.arima()</code> function from the forecast package is used. The functions <code>analysis()</code> and <code>assessment()</code> return the data frame, so another step converts the data in to a <code>ts</code> object called <code>mod_dat</code> using a function in the timetk package.</p>
<pre class="r"><code>library(forecast)  # for `auto.arima`
library(timetk)    # for `tk_ts`
library(zoo)       # for `as.yearmon`

fit_model &lt;- function(x, ...) {
  # suggested by Matt Dancho:
  x %&gt;%
    analysis() %&gt;%
    # Since the first day changes over resamples, adjust it
    # based on the first date value in the data frame 
    tk_ts(start = .$date[[1]] %&gt;% as.yearmon(), 
          frequency = 12, 
          silent = TRUE) %&gt;%
    auto.arima(...)
}</code></pre>
<p>Each model is saved in a new column:</p>
<pre class="r"><code>roll_rs$arima &lt;- map(roll_rs$splits, fit_model)

# For example:
roll_rs$arima[[1]]
#&gt; Series: . 
#&gt; ARIMA(4,1,1)(0,1,2)[12] 
#&gt; 
#&gt; Coefficients:
#&gt;           ar1      ar2     ar3      ar4      ma1    sma1     sma2
#&gt;       -0.1852  -0.0238  0.3577  -0.1517  -0.8311  -0.193  -0.3244
#&gt; s.e.   0.1466   0.1656  0.1440   0.0809   0.1377   0.067   0.0640
#&gt; 
#&gt; sigma^2 estimated as 72198:  log likelihood=-1591.15
#&gt; AIC=3198.3   AICc=3198.97   BIC=3225.7</code></pre>
<p>(There are some warnings produced by these first regarding extra columns in the data that can be ignored)</p>
<p>Using the model fits, performance will be measured in two ways:</p>
<ul>
<li><em>interpolation</em> error will measure how well the model fits to the data that were used to create the model. This is most likely optimistic since no holdout method is used.</li>
<li><em>extrapolation</em> or <em>forecast</em> error evaluates the efficacy of the model on the data from the following year (that were not used in the model fit).</li>
</ul>
<p>In each case, the mean absolute percent error (MAPE) is the statistic used to characterize the model fits. The interpolation error can be computed from the <code>Arima</code> object. to make things easy, the sweep package’s <code>sw_glance()</code> function is used:</p>
<pre class="r"><code>library(sweep)

roll_rs$interpolation &lt;- map_dbl(
  roll_rs$arima,
  function(x) 
    sw_glance(x)[[&quot;MAPE&quot;]]
  )
summary(roll_rs$interpolation)
#&gt;    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
#&gt;   2.841   2.921   2.950   2.947   2.969   3.135</code></pre>
<p>For the extrapolation error, the model and split objects are required. Using these:</p>
<pre class="r"><code>get_extrap &lt;- function(split, mod) {
  n &lt;- nrow(assessment(split))
  # Get assessment data
  pred_dat &lt;- assessment(split) %&gt;%
    mutate(
      pred = as.vector(forecast(mod, h = n)$mean),
      pct_error = ( S4248SM144NCEN - pred ) / S4248SM144NCEN * 100
    )
  mean(abs(pred_dat$pct_error))
}

roll_rs$extrapolation &lt;- 
  map2_dbl(roll_rs$splits, roll_rs$arima, get_extrap)

summary(roll_rs$extrapolation)
#&gt;    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
#&gt;   2.371   3.227   3.629   3.653   4.113   5.453</code></pre>
<p>What do these error estimates look like over time?</p>
<pre class="r"><code>roll_rs %&gt;%
  select(interpolation, extrapolation, start_date) %&gt;%
  pivot_longer(cols = matches(&quot;ation&quot;), names_to = &quot;error&quot;, values_to = &quot;MAPE&quot;) %&gt;%
  ggplot(aes(x = start_date, y = MAPE, col = error)) + 
  geom_point() + 
  geom_line()</code></pre>
<p><img src="figs/plot-1.svg" width="672" /></p>
<p>It is likely that the interpolation error is an underestimate to some degree.</p>
<p>It is also worth noting that <code>rolling_origin()</code> can be used over calendar periods, rather than just over a fixed window size. This is especially useful for irregular series where a fixed window size might not make sense because of missing data points, or because of calendar features like different months having a different number of days.</p>
<p>The example below demonstrates this idea by splitting <code>drinks</code> into a nested set of 26 years, and rolling over years rather than months. Note that the end result accomplishes a different task than the original example, in this case, each slice moves forward an entire year, rather than just one month.</p>
<pre class="r"><code># The idea is to nest by the period to roll over,
# which in this case is the year.
roll_rs_annual &lt;- drinks %&gt;%
  mutate(year = as.POSIXlt(date)$year + 1900) %&gt;%
  nest(data = c(date, S4248SM144NCEN)) %&gt;%
  rolling_origin(
    initial = 20, 
    assess = 1, 
    cumulative = FALSE
  )

analysis(roll_rs_annual$splits[[1]])
#&gt; # A tibble: 20 x 2
#&gt;     year data             
#&gt;    &lt;dbl&gt; &lt;list&gt;           
#&gt;  1  1992 &lt;tibble [12 × 2]&gt;
#&gt;  2  1993 &lt;tibble [12 × 2]&gt;
#&gt;  3  1994 &lt;tibble [12 × 2]&gt;
#&gt;  4  1995 &lt;tibble [12 × 2]&gt;
#&gt;  5  1996 &lt;tibble [12 × 2]&gt;
#&gt;  6  1997 &lt;tibble [12 × 2]&gt;
#&gt;  7  1998 &lt;tibble [12 × 2]&gt;
#&gt;  8  1999 &lt;tibble [12 × 2]&gt;
#&gt;  9  2000 &lt;tibble [12 × 2]&gt;
#&gt; 10  2001 &lt;tibble [12 × 2]&gt;
#&gt; 11  2002 &lt;tibble [12 × 2]&gt;
#&gt; 12  2003 &lt;tibble [12 × 2]&gt;
#&gt; 13  2004 &lt;tibble [12 × 2]&gt;
#&gt; 14  2005 &lt;tibble [12 × 2]&gt;
#&gt; 15  2006 &lt;tibble [12 × 2]&gt;
#&gt; 16  2007 &lt;tibble [12 × 2]&gt;
#&gt; 17  2008 &lt;tibble [12 × 2]&gt;
#&gt; 18  2009 &lt;tibble [12 × 2]&gt;
#&gt; 19  2010 &lt;tibble [12 × 2]&gt;
#&gt; 20  2011 &lt;tibble [12 × 2]&gt;</code></pre>
<p>The workflow to access these calendar slices is to use <code>bind_rows()</code> to join
each analysis set together.</p>
<pre class="r"><code>mutate(
  roll_rs_annual,
  extracted_slice = map(splits, ~ bind_rows(analysis(.x)$data))
)
#&gt; # Rolling origin forecast resampling 
#&gt; # A tibble: 6 x 3
#&gt;   splits         id     extracted_slice   
#&gt; * &lt;list&gt;         &lt;chr&gt;  &lt;list&gt;            
#&gt; 1 &lt;split [20/1]&gt; Slice1 &lt;tibble [240 × 2]&gt;
#&gt; 2 &lt;split [20/1]&gt; Slice2 &lt;tibble [240 × 2]&gt;
#&gt; 3 &lt;split [20/1]&gt; Slice3 &lt;tibble [240 × 2]&gt;
#&gt; 4 &lt;split [20/1]&gt; Slice4 &lt;tibble [240 × 2]&gt;
#&gt; 5 &lt;split [20/1]&gt; Slice5 &lt;tibble [240 × 2]&gt;
#&gt; 6 &lt;split [20/1]&gt; Slice6 &lt;tibble [240 × 2]&gt;</code></pre>
</div>
<div id="session-information" class="section level1">
<h1>Session information</h1>
<pre><code>#&gt; ─ Session info ───────────────────────────────────────────────────────────────
#&gt;  setting  value                       
#&gt;  version  R version 3.6.1 (2019-07-05)
#&gt;  os       macOS Mojave 10.14.6        
#&gt;  system   x86_64, darwin15.6.0        
#&gt;  ui       X11                         
#&gt;  language (EN)                        
#&gt;  collate  en_US.UTF-8                 
#&gt;  ctype    en_US.UTF-8                 
#&gt;  tz       America/New_York            
#&gt;  date     2020-03-26                  
#&gt; 
#&gt; ─ Packages ───────────────────────────────────────────────────────────────────
#&gt;  package    * version    date       lib source                             
#&gt;  broom      * 0.5.4      2020-01-27 [1] CRAN (R 3.6.0)                     
#&gt;  dials      * 0.0.4      2019-12-02 [1] CRAN (R 3.6.1)                     
#&gt;  dplyr      * 0.8.5      2020-03-07 [1] CRAN (R 3.6.0)                     
#&gt;  forecast   * 8.9        2019-08-22 [1] CRAN (R 3.6.0)                     
#&gt;  ggplot2    * 3.3.0      2020-03-05 [1] CRAN (R 3.6.0)                     
#&gt;  infer      * 0.5.1      2019-11-19 [1] CRAN (R 3.6.0)                     
#&gt;  parsnip    * 0.0.5.9000 2020-03-26 [1] local                              
#&gt;  purrr      * 0.3.3      2019-10-18 [1] CRAN (R 3.6.0)                     
#&gt;  recipes    * 0.1.10     2020-03-18 [1] CRAN (R 3.6.1)                     
#&gt;  rlang        0.4.5.9000 2020-03-21 [1] Github (r-lib/rlang@a90b04b)       
#&gt;  rsample    * 0.0.5.9000 2020-03-23 [1] Github (tidymodels/rsample@4fdbd6c)
#&gt;  sweep      * 0.2.2      2019-10-08 [1] CRAN (R 3.6.0)                     
#&gt;  tibble     * 2.1.3      2019-06-06 [1] CRAN (R 3.6.0)                     
#&gt;  tidymodels * 0.1.0      2020-02-16 [1] CRAN (R 3.6.0)                     
#&gt;  timetk     * 0.1.2      2019-09-25 [1] CRAN (R 3.6.0)                     
#&gt;  tune       * 0.0.1.9000 2020-03-21 [1] Github (tidymodels/tune@6694258)   
#&gt;  workflows  * 0.1.0      2019-12-30 [1] CRAN (R 3.6.1)                     
#&gt;  yardstick  * 0.0.5      2020-01-23 [1] CRAN (R 3.6.0)                     
#&gt;  zoo        * 1.8-7      2020-01-10 [1] CRAN (R 3.6.0)                     
#&gt; 
#&gt; [1] /Library/Frameworks/R.framework/Versions/3.6/Resources/library</code></pre>
</div>
